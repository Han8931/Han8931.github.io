<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Svm - Tag - Han&#39;s XYZ</title>
        <link>http://localhost:1313/tags/svm/</link>
        <description>Svm - Tag - Han&#39;s XYZ</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>tabularasa8931@gmail.com (Han)</managingEditor>
            <webMaster>tabularasa8931@gmail.com (Han)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 25 Aug 2024 00:00:00 &#43;0000</lastBuildDate><atom:link href="http://localhost:1313/tags/svm/" rel="self" type="application/rss+xml" /><item>
    <title>Introduction to Support Vector Machines Part 1.</title>
    <link>http://localhost:1313/20240825_svm1/</link>
    <pubDate>Sun, 25 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>Han</author>
    <guid>http://localhost:1313/20240825_svm1/</guid>
    <description><![CDATA[Support Vector Machine Introduction Support Vector Machines (SVMs) are among the most effective and versatile tools in machine learning, widely used for various tasks. SVMs work by finding the optimal boundary, or hyperplane, that separates different classes of data with the maximum margin, making them highly reliable for classification, especially with complex datasets.
What truly sets SVMs apart is their ability to handle both linear and non-linear data through the kernel trick, allowing them to adapt to a wide range of problems with impressive accuracy.]]></description>
</item>
</channel>
</rss>
